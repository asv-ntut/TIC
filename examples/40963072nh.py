# import argparse
# import json
# import math
# import os
# import sys
# import time
# from collections import defaultdict, OrderedDict
# from typing import List
#
# import torch
# import torch.nn as nn
# import torch.nn.functional as F
# from PIL import Image
# from pytorch_msssim import ms_ssim
# from torchvision import transforms
#
# import compressai
# from compressai.ans import BufferedRansEncoder, RansDecoder
# from compressai.datasets import ImageFolder
# from compressai.entropy_models import EntropyBottleneck, GaussianConditional
# # âœ¨ ä¿®æ”¹ï¼šå¾ compressai.models.utils å°å…¥ conv
# from compressai.models.utils import conv, update_registered_buffers
# from compressai.zoo import image_models as pretrained_models
# from compressai.zoo import load_state_dict
# from compressai.zoo.image import model_architectures as architectures
#
# # ==============================================================================
# # (æ‚¨çš„æ¨¡å‹å®šç¾©å’Œè¼”åŠ©å‡½å¼... ä¿æŒä¸è®Š)
# # ==============================================================================
#
# # --- æ¨¡å‹ update æ™‚éœ€è¦çš„è¼”åŠ©å‡½å¼ ---
# SCALES_MIN = 0.11
# SCALES_MAX = 256
# SCALES_LEVELS = 64
#
#
# def get_scale_table(min=SCALES_MIN, max=SCALES_MAX, levels=SCALES_LEVELS):
#     return torch.exp(torch.linspace(math.log(min), math.log(max), levels))
#
#
# # --- (è¼”åŠ©å‡½å¼) conv å’Œ deconv ---
# def deconv(in_channels, out_channels, kernel_size=5, stride=2):
#     return nn.ConvTranspose2d(
#         in_channels,
#         out_channels,
#         kernel_size=kernel_size,
#         stride=stride,
#         output_padding=stride - 1,
#         padding=kernel_size // 2,
#     )
#
#
# # --- âœ¨ æ–°å¢ï¼šå¾è¨“ç·´è…³æœ¬è¤‡è£½éä¾†çš„ PixelShuffle è¼”åŠ©å‡½å¼ ---
# def deconv_pixelshuffle(in_channels, out_channels, kernel_size=5, stride=2):
#     internal_channels = out_channels * (stride ** 2)
#     return nn.Sequential(
#         nn.Conv2d(
#             in_channels,
#             internal_channels,
#             kernel_size=kernel_size,
#             stride=1,
#             padding=kernel_size // 2,
#         ),
#         nn.PixelShuffle(upscale_factor=stride)
#     )
#
#
# # --- âœ¨ æ›¿æ›ï¼šä½¿ç”¨è¨“ç·´è…³æœ¬çš„æ¨¡å‹å®šç¾© ---
#
# class SimpleConvStudentModel(nn.Module):
#     def __init__(self, N=128, M=192):  # ä½¿ç”¨è¨“ç·´è…³æœ¬çš„é è¨­å€¼
#         super().__init__()
#         self.N, self.M = N, M
#
#         # g_a: Encoder (èˆ‡è¨“ç·´è…³æœ¬ä¸€è‡´ï¼ŒåŒ…å« BatchNorm)
#         self.g_a = nn.Sequential(
#             conv(3, N, kernel_size=5, stride=2), nn.BatchNorm2d(N), nn.ReLU(inplace=True),
#             conv(N, N, kernel_size=3, stride=2), nn.BatchNorm2d(N), nn.ReLU(inplace=True),
#             conv(N, N, kernel_size=3, stride=2), nn.BatchNorm2d(N), nn.ReLU(inplace=True),
#             conv(N, M, kernel_size=3, stride=2),  # Output is M channels
#         )
#
#         # g_s: Decoder (èˆ‡è¨“ç·´è…³æœ¬ä¸€è‡´ï¼Œä½¿ç”¨ PixelShuffle å’Œ BatchNorm)
#         self.g_s = nn.Sequential(
#             deconv_pixelshuffle(M, N, kernel_size=3, stride=2),
#             nn.BatchNorm2d(N),
#             nn.ReLU(inplace=True),
#
#             deconv_pixelshuffle(N, N, kernel_size=3, stride=2),
#             nn.BatchNorm2d(N),
#             nn.ReLU(inplace=True),
#
#             deconv_pixelshuffle(N, N, kernel_size=3, stride=2),
#             nn.BatchNorm2d(N),
#             nn.ReLU(inplace=True),
#
#             deconv_pixelshuffle(N, 3, kernel_size=5, stride=2),
#         )
#
#         # h_a: Hyper Encoder (èˆ‡è¨“ç·´è…³æœ¬ä¸€è‡´)
#         self.h_a = nn.Sequential(
#             conv(M, N, kernel_size=3, stride=1), nn.ReLU(inplace=True),  # Input is M channels
#             conv(N, N, kernel_size=3, stride=2), nn.ReLU(inplace=True),
#             conv(N, N, kernel_size=3, stride=2)  # Output is N channels
#         )
#
#         # h_s: Hyper-Prior Decoder (èˆ‡è¨“ç·´è…³æœ¬ä¸€è‡´ï¼Œä½¿ç”¨ PixelShuffle)
#         self.h_s = nn.Sequential(
#             deconv_pixelshuffle(N, N, kernel_size=3, stride=2),
#             nn.ReLU(inplace=True),
#
#             deconv_pixelshuffle(N, N, kernel_size=3, stride=2),
#             nn.ReLU(inplace=True),
#
#             conv(N, M * 2, kernel_size=3, stride=1)  # Output is 2*M channels
#         )
#
#         self.entropy_bottleneck = EntropyBottleneck(N)
#         self.gaussian_conditional = GaussianConditional(None)
#         self.apply(self._init_weights)
#
#     def forward(self, x):
#         y = self.g_a(x)  # [B, M, H/16, W/16]
#         z = self.h_a(y)  # [B, N, H/64, W/64]
#         z_hat, z_likelihoods = self.entropy_bottleneck(z)
#         gaussian_params = self.h_s(z_hat)  # [B, 2*M, H/16, W/16]
#         scales_hat, means_hat = gaussian_params.chunk(2, 1)
#         y_hat, y_likelihoods = self.gaussian_conditional(y, scales_hat, means=means_hat)  # [B, M, H/16, W/16]
#         x_hat = self.g_s(y_hat)  # [B, 3, H, W]
#
#         return {
#             "x_hat": x_hat,
#             "likelihoods": {"y": y_likelihoods, "z": z_likelihoods},
#             "y_hat": y_hat,
#             "z_hat": z_hat
#         }
#
#     def aux_loss(self):
#         return sum(m.loss() for m in self.modules() if isinstance(m, EntropyBottleneck))
#
#     def _init_weights(self, m):
#         if isinstance(m, (nn.Conv2d, nn.ConvTranspose2d)):
#             nn.init.kaiming_normal_(m.weight, mode='fan_out', nonlinearity='relu')
#             if m.bias is not None: nn.init.constant_(m.bias, 0)
#
#     def update(self, scale_table=None, force=False):
#         if scale_table is None: scale_table = get_scale_table()
#         self.gaussian_conditional.update_scale_table(scale_table, force=force)
#         updated = any(m.update(force=force) for m in self.modules() if isinstance(m, EntropyBottleneck))
#         return updated
#
#     def load_state_dict(self, state_dict, strict=True):
#         update_registered_buffers(
#             self.entropy_bottleneck,
#             "entropy_bottleneck",
#             ["_quantized_cdf", "_offset", "_cdf_length"],
#             state_dict,
#         )
#         update_registered_buffers(
#             self.gaussian_conditional,
#             "gaussian_conditional",
#             ["_quantized_cdf", "_offset", "_cdf_length", "scale_table"],
#             state_dict,
#         )
#         super().load_state_dict(state_dict, strict=strict)
#
#     @classmethod
#     def from_state_dict(cls, state_dict):
#         try:
#             first_g_a_weight_key = 'g_a.0.weight'
#             if first_g_a_weight_key not in state_dict:
#                 g_a_weight_keys = sorted([k for k in state_dict if k.startswith('g_a.') and k.endswith('.weight')])
#                 if not g_a_weight_keys: raise KeyError("No g_a weights found in state_dict for N")
#                 first_g_a_weight_key = g_a_weight_keys[0]
#             N = state_dict[first_g_a_weight_key].size(0)
#         except Exception as e:
#             print(f"Error inferring N in from_state_dict: {e}. Assuming default N=128.")
#             N = 128
#
#         try:
#             g_a_weight_keys = sorted([k for k in state_dict if k.startswith('g_a.') and k.endswith('.weight')])
#             if not g_a_weight_keys: raise KeyError("No g_a weights found in state_dict for M")
#             last_g_a_weight_key = g_a_weight_keys[-1]
#             expected_key = 'g_a.9.weight'
#             if expected_key in state_dict:
#                 M = state_dict[expected_key].size(0)
#             else:
#                 print(
#                     f"Warning: Expected key '{expected_key}' not found. Inferring M from last g_a key: '{last_g_a_weight_key}'")
#                 M = state_dict[last_g_a_weight_key].size(0)
#         except Exception as e:
#             print(f"Error inferring M in from_state_dict: {e}. Assuming default M=192.")
#             M = 192
#
#         print(f"åµæ¸¬åˆ°æ¨¡å‹çµæ§‹: N={N}, M={M} (ä½¿ç”¨ BatchNorm å’Œ PixelShuffle)")
#         net = cls(N, M)
#         net.load_state_dict(state_dict, strict=False)
#         return net
#
#     def compress(self, x):
#         y = self.g_a(x)
#         z = self.h_a(y)
#         z_strings = self.entropy_bottleneck.compress(z)
#         z_hat = self.entropy_bottleneck.decompress(z_strings, z.size()[-2:])
#         gaussian_params = self.h_s(z_hat)
#         scales_hat, means_hat = gaussian_params.chunk(2, 1)
#         indexes = self.gaussian_conditional.build_indexes(scales_hat)
#         y_strings = self.gaussian_conditional.compress(y, indexes, means=means_hat)
#         return {"strings": [y_strings, z_strings], "shape": z.size()[-2:]}
#
#     def decompress(self, strings, shape):
#         assert isinstance(strings, list) and len(strings) == 2
#         z_hat = self.entropy_bottleneck.decompress(strings[1], shape)
#         gaussian_params = self.h_s(z_hat)
#         scales_hat, means_hat = gaussian_params.chunk(2, 1)
#         indexes = self.gaussian_conditional.build_indexes(scales_hat)
#         y_hat = self.gaussian_conditional.decompress(strings[0], indexes, means=means_hat)
#         x_hat = self.g_s(y_hat).clamp_(0, 1)
#         return {"x_hat": x_hat}
#
#
# # ==============================================================================
# # (è¼”åŠ©å‡½å¼... ä¿æŒä¸è®Š)
# # ==============================================================================
#
# architectures["simple_conv_student"] = SimpleConvStudentModel
# torch.backends.cudnn.deterministic = True
# torch.set_num_threads(1)
# IMG_EXTENSIONS = (".jpg", ".jpeg", ".png", ".ppm", ".bmp", ".pgm", ".tif", ".tiff", ".webp")
#
#
# def collect_images(rootpath: str) -> List[str]:
#     return [os.path.join(rootpath, f) for f in os.listdir(rootpath) if
#             os.path.splitext(f)[-1].lower() in IMG_EXTENSIONS]
#
#
# def psnr(a: torch.Tensor, b: torch.Tensor) -> float:
#     mse = F.mse_loss(a, b).item()
#     return -10 * math.log10(mse) if mse > 0 else float('inf')
#
#
# def read_image(filepath: str) -> torch.Tensor:
#     assert os.path.isfile(filepath)
#     img = Image.open(filepath).convert("RGB")
#     return transforms.ToTensor()(img)
#
#
# # ==============================================================================
# # (inference å‡½å¼ä¿æŒä¸è®Š - "ç„¡ header" ç‰ˆæœ¬)
# # ==============================================================================
# @torch.no_grad()
# def inference(model, x, save=False, output_dir=None, base_filename=None, patch_index=None):
#     # x æ‡‰è©²æ˜¯ [3, 256, 256] çš„ TENSOR
#
#     x = x.unsqueeze(0)  # è®Šæˆ [1, 3, 256, 256]
#
#     h, w = x.size(2), x.size(3)  # h=256, w=256
#
#     # ä½ çš„æ¨¡å‹éœ€è¦ 64 çš„å€æ•¸ï¼Œæ‰€ä»¥ 256 æœƒè¢«å¡«å……åˆ° 320
#     p = 64
#     new_h = (h + p - 1) // p * p
#     new_w = (w + p - 1) // p * p
#     padding_left = (new_w - w) // 2
#     padding_right = new_w - w - padding_left
#     padding_top = (new_h - h) // 2
#     padding_bottom = new_h - h - padding_top
#
#     # x_padded è®Šæˆ [1, 3, 320, 320]
#     x_padded = F.pad(x, (padding_left, padding_right, padding_top, padding_bottom), mode="constant", value=0)
#
#     start = time.time()
#     # 1. å‘¼å« compress å‡½å¼
#     out_enc = model.compress(x_padded)
#     enc_time = time.time() - start
#
#     start = time.time()
#     # 2. å‘¼å« decompress å‡½å¼
#     out_dec = model.decompress(out_enc["strings"], out_enc["shape"])
#     dec_time = time.time() - start
#
#     # è£å‰ªå› 256x256
#     out_dec["x_hat"] = F.pad(out_dec["x_hat"], (-padding_left, -padding_right, -padding_top, -padding_bottom))
#
#     # è¨ˆç®— bpp (åŸºæ–¼ 256x256)
#     num_pixels = x.size(0) * x.size(2) * x.size(3)
#     bpp = sum(len(s[0]) for s in out_enc["strings"]) * 8.0 / num_pixels
#
#     # 3. æª¢æŸ¥æ˜¯å¦éœ€è¦å„²å­˜æª”æ¡ˆ
#     if save and output_dir is not None and base_filename is not None:
#
#         # --- å„²å­˜è§£å£“ç¸®çš„ .png æª”æ¡ˆ ---
#         reconstructed_img = transforms.ToPILImage()(out_dec["x_hat"].squeeze().cpu())
#         output_filepath = os.path.join(output_dir, f"{base_filename}_reconstructed.png")
#         reconstructed_img.save(output_filepath)
#
#         # --- å„²å­˜ .bin æª”æ¡ˆ ---
#         bin_filepath = os.path.join(output_dir, f"{base_filename}.bin")
#
#         # å¾å£“ç¸®è¼¸å‡ºä¸­æå–è³‡æ–™
#         y_string = out_enc["strings"][0][0]
#         z_string = out_enc["strings"][1][0]
#         shape = out_enc["shape"]  # é€™æ˜¯ z.size()[-2:]
#
#         try:
#             with open(bin_filepath, "wb") as f:
#
#                 # (ç„¡ header é‚è¼¯ï¼šä¸å¯«å…¥ patch_index)
#
#                 # 1. å¯«å…¥ shape (H, W)ï¼Œå„ 2 bytes (uint16_t)
#                 f.write(shape[0].to_bytes(2, 'little', signed=False))
#                 f.write(shape[1].to_bytes(2, 'little', signed=False))
#
#                 # 2. å¯«å…¥ z_string: é•·åº¦ 4 bytes (uint32_t) + åŸå§‹è³‡æ–™
#                 f.write(len(z_string).to_bytes(4, 'little', signed=False))
#                 f.write(z_string)
#
#                 # 3. å¯«å…¥ y_string: é•·åº¦ 4 bytes (uint32_t) + åŸå§‹è³‡æ–™
#                 f.write(len(y_string).to_bytes(4, 'little', signed=False))
#                 f.write(y_string)
#
#         except Exception as e:
#             print(f"Error saving bitstream: {e}")
#         # --- Så„²å­˜é‚è¼¯çµæŸ ---
#
#     return {"psnr": psnr(x, out_dec["x_hat"]), "ms-ssim": ms_ssim(x, out_dec["x_hat"], data_range=1.0).item(),
#             "bpp": bpp, "encoding_time": enc_time, "decoding_time": dec_time}
#
#
# # ==============================================================================
# # (inference_entropy_estimation å‡½å¼ä¿æŒä¸è®Š)
# # ==============================================================================
# @torch.no_grad()
# def inference_entropy_estimation(model, x):
#     x = x.unsqueeze(0)
#     start = time.time()
#     out_net = model.forward(x)
#     elapsed_time = time.time() - start
#     num_pixels = x.size(0) * x.size(2) * x.size(3)
#     bpp = sum(
#         (torch.log(likelihoods).sum() / (-math.log(2) * num_pixels)) for likelihoods in
#         out_net["likelihoods"].values())
#     return {"psnr": psnr(x, out_net["x_hat"]), "bpp": bpp.item(), "encoding_time": elapsed_time / 2.0,
#             "decoding_time": elapsed_time / 2.0}
#
#
# # ==============================================================================
# # (load_pretrained å’Œ load_checkpoint å‡½å¼ä¿æŒä¸è®Š)
# # ==============================================================================
# def load_pretrained(model: str, metric: str, quality: int) -> nn.Module:
#     return pretrained_models[model](quality=quality, metric=metric, pretrained=True).eval()
#
#
# def load_checkpoint(arch: str, checkpoint_path: str) -> nn.Module:
#     print(f"æ­£åœ¨å¾ {checkpoint_path} è¼‰å…¥æ¬Šé‡...")
#     checkpoint = torch.load(checkpoint_path, map_location=lambda storage, loc: storage)
#     state_dict = checkpoint.get("state_dict", checkpoint)
#
#     clean_state_dict = OrderedDict()
#     is_dataparallel = False
#     for k, v in state_dict.items():
#         if k.startswith('module.'):
#             is_dataparallel = True
#             name = k[7:]  # remove 'module.'
#         else:
#             name = k
#         clean_state_dict[name] = v
#
#     if is_dataparallel:
#         print("åµæ¸¬åˆ° 'module.' å‰ç¶´ï¼Œå·²è‡ªå‹•ç§»é™¤ã€‚")
#
#     return architectures[arch].from_state_dict(clean_state_dict).eval()
#
#
# # ==============================================================================
# # (eval_model å‡½å¼ä¿æŒä¸è®Š)
# # ==============================================================================
# def eval_model(model, filepaths, entropy_estimation=False, half=False, save=False, output_dir=None):
#     device = next(model.parameters()).device
#
#     # é€™å€‹ metrics å°‡å„²å­˜æ‰€æœ‰ "å¤§å‹åœ–ç‰‡" çš„ "å¹³å‡" æŒ‡æ¨™
#     metrics = defaultdict(float)
#
#     PATCH_SIZE = 256
#     EXPECTED_W = 4096
#     EXPECTED_H = 3072
#
#     # å–å¾— Pytorch çš„ ToTensor è½‰æ›å™¨ (æˆ‘å€‘åªåœ¨è¿´åœˆå…§ä½¿ç”¨)
#     to_tensor_transform = transforms.ToTensor()
#
#     # è¿´åœˆéæ­·ä½  "dataset" è³‡æ–™å¤¾ä¸­çš„æ¯ä¸€å¼µ "å¤§å‹åœ–ç‰‡"
#     for i, f in enumerate(filepaths):
#         print(f"\n--- æ­£åœ¨é–‹å•Ÿå¤§å‹å½±åƒ {i + 1}/{len(filepaths)}: {os.path.basename(f)} ---")
#
#         img_large = None
#         try:
#             # âœ¨ã€é‡é»ã€‘ä½¿ç”¨ Pillow é–‹å•Ÿå½±åƒ (lazy loadingï¼Œä¸ä½”è¨˜æ†¶é«”)
#             img_large = Image.open(f).convert("RGB")
#         except Exception as e:
#             print(f"  éŒ¯èª¤ï¼šç„¡æ³•è®€å–å½±åƒ {f}ã€‚éŒ¯èª¤è¨Šæ¯: {e}ã€‚è·³éæ­¤æª”æ¡ˆã€‚")
#             if img_large: img_large.close()
#             continue
#
#         # ç²å–å½±åƒå°ºå¯¸ (Pillow .size æ˜¯ (W, H))
#         img_w, img_h = img_large.size
#
#         if img_w != EXPECTED_W or img_h != EXPECTED_H:
#             print(f"  è­¦å‘Šï¼šå½±åƒ '{os.path.basename(f)}' çš„å¤§å°ä¸æ˜¯ {EXPECTED_W}x{EXPECTED_H} (è€Œæ˜¯ {img_w}x{img_h})ã€‚")
#             print("  å°‡ç¹¼çºŒå˜—è©¦åˆ‡å‰²ï¼Œä½†å¯èƒ½ä¸æ˜¯ 192 å¼µã€‚")
#
#         num_patches_x = img_w // PATCH_SIZE  # 4096 // 256 = 16
#         num_patches_y = img_h // PATCH_SIZE  # 3072 // 256 = 12
#         total_patches = num_patches_y * num_patches_x  # 12 * 16 = 192
#
#         if total_patches == 0:
#             print(f"  éŒ¯èª¤ï¼šå½±åƒå¤ªå°ï¼Œç„¡æ³•åˆ‡å‰²æˆ {PATCH_SIZE}x{PATCH_SIZE} çš„å€å¡Šã€‚è·³éæ­¤å½±åƒã€‚")
#             img_large.close()
#             continue
#
#         print(f"  å½±åƒå°‡è¢«åˆ‡å‰²æˆ {num_patches_y} (é«˜) x {num_patches_x} (å¯¬) = {total_patches} å¼µ 256x256 å€å¡Šã€‚")
#
#         # å–å¾—å¤§åœ–çš„åŸºç¤æª”å (ä¾‹å¦‚ "Tokyo_cropped_4096x3072")
#         base_filename_large = os.path.splitext(os.path.basename(f))[0]
#
#         # å„²å­˜é€™å¼µå¤§åœ– (192å€‹å€å¡Š) çš„æ‰€æœ‰æŒ‡æ¨™
#         patch_metrics_list = []
#         patch_index = 0
#
#         # âœ¨ã€é‡é»ã€‘å·¢ç‹€è¿´åœˆï¼šå¾ä¸Šåˆ°ä¸‹ (y), å¾å·¦åˆ°å³ (x)
#         try:
#             for y_idx in range(num_patches_y):  # 0 åˆ° 11
#                 for x_idx in range(num_patches_x):  # 0 åˆ° 15
#
#                     print(f"    è™•ç†å€å¡Š {patch_index + 1}/{total_patches} (Row {y_idx}, Col {x_idx})...", end="")
#
#                     # 1. âœ¨ã€æ‰‹åˆ»ã€‘è¨ˆç®—è£åˆ‡åº§æ¨™ (left, upper, right, lower)
#                     left = x_idx * PATCH_SIZE
#                     upper = y_idx * PATCH_SIZE
#                     right = left + PATCH_SIZE
#                     lower = upper + PATCH_SIZE
#                     box = (left, upper, right, lower)
#
#                     # 2. âœ¨ã€æ‰‹åˆ»ã€‘ä½¿ç”¨ Pillow è£åˆ‡ 256x256 å€å¡Š
#                     #    (é€™æ™‚æ‰çœŸæ­£å¾ç£ç¢Ÿè®€å–é€™ 256x256 çš„åƒç´ )
#                     patch_img = img_large.crop(box)  # é€™æ˜¯ä¸€å€‹ PIL Image ç‰©ä»¶
#
#                     # 3. âœ¨ã€æ‰‹åˆ»ã€‘åªå°‡é€™å€‹å°å€å¡Šè½‰ç‚º Tensor
#                     x_patch = to_tensor_transform(patch_img).to(device)  # [3, 256, 256]
#
#                     if half:
#                         model = model.half()
#                         x_patch = x_patch.half()
#
#                     # 4. å®šç¾©é€™å€‹å€å¡Šçš„æª”æ¡ˆåç¨±
#                     patch_base_filename = f"{base_filename_large}_patch_{patch_index:03d}"
#
#                     # 5. åŸ·è¡Œæ¨è«– (å£“ç¸®èˆ‡è§£å£“ç¸®)
#                     if not entropy_estimation:
#                         # å‘¼å«æˆ‘å€‘ä¿®æ”¹éçš„ inference å‡½å¼
#                         rv = inference(model,
#                                        x_patch,
#                                        save,  # å‚³é --save åƒæ•¸
#                                        output_dir,  # å‚³éè¼¸å‡ºè³‡æ–™å¤¾
#                                        patch_base_filename,  # âœ¨ å‚³é "å€å¡Šæª”å"
#                                        patch_index)  # âœ¨ å‚³é "å€å¡Šç·¨è™Ÿ" (ä½† inference å‡½å¼æœƒå¿½ç•¥å®ƒ)
#                     else:
#                         rv = inference_entropy_estimation(model, x_patch)
#
#                     print(f" PSNR: {rv['psnr']:.2f} dB, BPP: {rv['bpp']:.4f}")
#                     patch_metrics_list.append(rv)
#                     patch_index += 1
#
#                     # (æ‰‹å‹•é‡‹æ”¾ patch_img å’Œ x_patch è¨˜æ†¶é«”ï¼Œé›–ç„¶ Python æœƒè‡ªå‹•å›æ”¶ï¼Œ
#                     #  ä½†åœ¨åµŒå…¥å¼ç³»çµ±ä¸Šæ˜ç¢º del ç¸½æ˜¯æœ‰ç›Šçš„)
#                     del patch_img
#                     del x_patch
#
#         finally:
#             # âœ¨ã€é‡é»ã€‘ç¢ºä¿é—œé–‰å¤§å‹å½±åƒçš„æª”æ¡ˆæ§åˆ¶ä»£ç¢¼
#             if img_large:
#                 img_large.close()
#                 print(f"  --- å·²é—œé–‰å½±åƒæª”æ¡ˆ: {os.path.basename(f)} ---")
#
#         # --- è™•ç†å®Œä¸€å¼µå¤§åœ– (192å€‹å€å¡Š) ---
#
#         # è¨ˆç®—é€™å¼µå¤§åœ–çš„ "å¹³å‡" æŒ‡æ¨™
#         avg_metrics_large = defaultdict(float)
#         if not patch_metrics_list: continue
#
#         for rv in patch_metrics_list:
#             for k, v in rv.items():
#                 avg_metrics_large[k] += v
#
#         print(f"  --- å¤§å‹å½±åƒ '{os.path.basename(f)}' å¹³å‡çµ±è¨ˆ ---")
#         for k, v in avg_metrics_large.items():
#             avg_metrics_large[k] = v / total_patches
#             print(f"    Avg. {k}: {avg_metrics_large[k]:.4f}")
#
#         # å°‡é€™å¼µå¤§åœ–çš„å¹³å‡æŒ‡æ¨™ï¼Œç´¯åŠ åˆ° "ç¸½æŒ‡æ¨™" ä¸­
#         for k, v in avg_metrics_large.items():
#             metrics[k] += v
#
#     # --- è™•ç†å®Œæ‰€æœ‰å¤§åœ– ---
#
#     if not filepaths:
#         print("éŒ¯èª¤ï¼šæœªæä¾›ä»»ä½•å½±åƒé€²è¡Œè©•ä¼°ã€‚")
#         return metrics
#
#     # è¨ˆç®— "æ‰€æœ‰" å¤§åœ–çš„ "ç¸½å¹³å‡" æŒ‡æ¨™
#     for k, v in metrics.items():
#         metrics[k] = v / len(filepaths)
#
#     if save:
#         print(f"\nè™•ç†å®Œæˆã€‚å·²å„²å­˜æ‰€æœ‰ .bin å’Œ .png æª”æ¡ˆè‡³: {output_dir}")
#
#     return metrics
#
#
# # ==============================================================================
# # (setup_args å’Œ main å‡½å¼)
# # ==============================================================================
#
# def setup_args():
#     parent_parser = argparse.ArgumentParser(add_help=False)
#     parent_parser.add_argument("dataset", type=str, help="dataset path (åŒ…å« 4096x3072 å½±åƒçš„è³‡æ–™å¤¾)")
#     parent_parser.add_argument("-a", "--architecture", type=str, required=True,
#                                help="model architecture (e.g., simple_conv_student)")
#     parent_parser.add_argument("-c", "--entropy-coder", choices=compressai.available_entropy_coders(),
#                                default=compressai.available_entropy_coders()[0],
#                                help="entropy coder (default: %(default)s)")
#     parent_parser.add_argument("--cuda", action="store_true", help="enable CUDA")
#     parent_parser.add_argument("--half", action="store_true", help="convert model to half floating point (fp16)")
#     parent_parser.add_argument("--entropy-estimation", action="store_true",
#                                help="use evaluated entropy estimation (no entropy coding)")
#     parent_parser.add_argument("-v", "--verbose", action="store_true", help="verbose mode")
#     parent_parser.add_argument("--save", action="store_true", help="å„²å­˜åˆ‡å‰²å¾Œçš„ .bin å’Œè§£å£“ç¸®çš„ .png æª”æ¡ˆ")
#
#     # âœ¨âœ¨âœ¨ã€ä¿®æ”¹é»ï¼šæ›´æ”¹é è¨­è³‡æ–™å¤¾åç¨±ã€‘âœ¨âœ¨âœ¨
#     parent_parser.add_argument("-o", "--output_dir", type=str, default="no_header",
#                                help="å„²å­˜ 192 å€‹å€å¡Šæª”æ¡ˆçš„è³‡æ–™å¤¾ (default: %(default)s)")
#
#     parser = argparse.ArgumentParser(description="Evaluate a model by tiling large images.", add_help=True)
#     subparsers = parser.add_subparsers(help="model source", dest="source")
#
#     pretrained_parser = subparsers.add_parser("pretrained", parents=[parent_parser])
#     pretrained_parser.add_argument("-m", "--metric", type=str, choices=["mse", "ms-ssim"], default="mse",
#                                    help="metric trained against (default: %(default)s)")
#     pretrained_parser.add_argument("-q", "--quality", dest="qualities", nargs="+", type=int, default=(1,))
#
#     checkpoint_parser = subparsers.add_parser("checkpoint", parents=[parent_parser])
#     checkpoint_parser.add_argument("-p", "--path", dest="paths", type=str, nargs="*", required=True,
#                                    help="checkpoint path")
#     return parser
#
#
# def main(argv):
#     parser = setup_args()
#     args = parser.parse_args(argv)
#     if not args.source:
#         print("Error: missing 'checkpoint' or 'pretrained' source.", file=sys.stderr)
#         parser.print_help()
#         raise SystemExit(1)
#
#     # é€™è£¡çš„ filepaths æœƒåŒ…å«ä½  4096x3072 çš„ .tif å½±åƒ
#     filepaths = collect_images(args.dataset)
#     if len(filepaths) == 0:
#         print(f"Error: åœ¨ '{args.dataset}' è³‡æ–™å¤¾ä¸­æ‰¾ä¸åˆ°ä»»ä½•å½±åƒã€‚", file=sys.stderr)
#         raise SystemExit(1)
#
#     print(f"åœ¨ {args.dataset} ä¸­æ‰¾åˆ° {len(filepaths)} å¼µå½±åƒã€‚")
#
#     if args.save:
#         os.makedirs(args.output_dir, exist_ok=True)
#         print(f"åˆ‡å‰²å¾Œçš„ .bin å’Œ .png æª”æ¡ˆå°‡å„²å­˜è‡³: {args.output_dir}")
#
#     compressai.set_entropy_coder(args.entropy_coder)
#
#     if args.source == "pretrained":
#         runs = sorted(args.qualities)
#         opts = (args.architecture, args.metric)
#         load_func = load_pretrained
#         log_fmt = "\rEvaluating {0} | {run:d}"
#     elif args.source == "checkpoint":
#         runs = args.paths
#         opts = (args.architecture,)
#         load_func = load_checkpoint
#         log_fmt = "\rEvaluating {run:s}"
#
#     results = defaultdict(list)
#     for run in runs:
#         if args.verbose:
#             sys.stderr.write(log_fmt.format(*opts, run=run))
#             sys.stderr.flush()
#
#         model = load_func(*opts, run)
#         if args.cuda and torch.cuda.is_available():
#             model = model.to("cuda")
#             print("æ¨¡å‹å·²ç§»è‡³ CUDA")
#         else:
#             model = model.to("cpu")
#             print("æ¨¡å‹å·²ç§»è‡³ CPU")
#
#         if args.half and not args.cuda:
#             print("è­¦å‘Š: --half åƒæ•¸é€šå¸¸èˆ‡ --cuda ä¸€èµ·ä½¿ç”¨ã€‚åœ¨ CPU ä¸Šä½¿ç”¨ FP16 å¯èƒ½æœƒæ›´æ…¢æˆ–ä¸å—æ”¯æ´ã€‚")
#
#         if args.source == "checkpoint":
#             print("æ­£åœ¨æ›´æ–°æ¨¡å‹ (update CDFs)...")
#             model.update(force=True)
#             print("æ¨¡å‹æ›´æ–°å®Œç•¢ã€‚")
#
#         # å‘¼å«æˆ‘å€‘ä¿®æ”¹éçš„ eval_model
#         metrics = eval_model(model, filepaths, args.entropy_estimation, args.half, args.save, args.output_dir)
#         for k, v in metrics.items():
#             results[k].append(v)
#
#     if args.verbose:
#         sys.stderr.write("\n")
#         sys.stderr.flush()
#
#     description = ("entropy estimation" if args.entropy_estimation else args.entropy_coder)
#     output = {"name": args.architecture, "description": f"Inference ({description})", "results": results}
#
#     print("\n--- ç¸½é«”å¹³å‡æŒ‡æ¨™ (æ‰€æœ‰å¤§å‹å½±åƒçš„å¹³å‡) ---")
#     print(json.dumps(output, indent=2))
#
#
# if __name__ == "__main__":
#     main(sys.argv[1:])
import argparse
import json
import math
import os
import sys
import time
import subprocess  # <-- 1. ç‚ºäº†å‘¼å« tar å’Œ md5sum
import shutil  # <-- 2. ç‚ºäº†åˆªé™¤æš«å­˜è³‡æ–™å¤¾
from collections import defaultdict, OrderedDict
from typing import List

import torch
import torch.nn as nn
import torch.nn.functional as F
from PIL import Image
from pytorch_msssim import ms_ssim
from torchvision import transforms

# --- å‡è¨­ compressai å·²å®‰è£åœ¨ç’°å¢ƒä¸­ ---
try:
    import compressai
    from compressai.ans import BufferedRansEncoder, RansDecoder
    from compressai.entropy_models import EntropyBottleneck, GaussianConditional
    from compressai.models.utils import conv, update_registered_buffers
    from compressai.zoo import image_models as pretrained_models
    from compressai.zoo import load_state_dict
except ImportError:
    print("\néŒ¯èª¤ï¼šæ‰¾ä¸åˆ° 'compressai' å‡½å¼åº«ã€‚")
    print("è«‹ç¢ºä¿ä½ å·²ç¶“å•Ÿå‹•äº† (tic10) ç’°å¢ƒï¼Œä¸¦ä¸” compressai å·²å®‰è£ã€‚")
    sys.exit(1)

# ==============================================================================
# (æ‚¨çš„æ¨¡å‹å®šç¾©å’Œè¼”åŠ©å‡½å¼... ä¿æŒä¸è®Š)
# ==============================================================================

# --- æ¨¡å‹ update æ™‚éœ€è¦çš„è¼”åŠ©å‡½å¼ ---
SCALES_MIN = 0.11
SCALES_MAX = 256
SCALES_LEVELS = 64


def get_scale_table(min=SCALES_MIN, max=SCALES_MAX, levels=SCALES_LEVELS):
    return torch.exp(torch.linspace(math.log(min), math.log(max), levels))


# --- (è¼”åŠ©å‡½å¼) conv å’Œ deconv ---
def deconv(in_channels, out_channels, kernel_size=5, stride=2):
    return nn.ConvTranspose2d(
        in_channels, out_channels, kernel_size=kernel_size, stride=stride,
        output_padding=stride - 1, padding=kernel_size // 2,
    )


def deconv_pixelshuffle(in_channels, out_channels, kernel_size=5, stride=2):
    internal_channels = out_channels * (stride ** 2)
    return nn.Sequential(
        nn.Conv2d(
            in_channels, internal_channels, kernel_size=kernel_size,
            stride=1, padding=kernel_size // 2,
        ),
        nn.PixelShuffle(upscale_factor=stride)
    )


# --- ä½ çš„æ¨¡å‹å®šç¾© (SimpleConvStudentModel) ---
class SimpleConvStudentModel(nn.Module):
    def __init__(self, N=128, M=192):
        super().__init__()
        self.N, self.M = N, M
        # g_a: Encoder
        self.g_a = nn.Sequential(
            conv(3, N, kernel_size=5, stride=2), nn.BatchNorm2d(N), nn.ReLU(inplace=True),
            conv(N, N, kernel_size=3, stride=2), nn.BatchNorm2d(N), nn.ReLU(inplace=True),
            conv(N, N, kernel_size=3, stride=2), nn.BatchNorm2d(N), nn.ReLU(inplace=True),
            conv(N, M, kernel_size=3, stride=2),
        )
        # g_s: Decoder
        self.g_s = nn.Sequential(
            deconv_pixelshuffle(M, N, kernel_size=3, stride=2), nn.BatchNorm2d(N), nn.ReLU(inplace=True),
            deconv_pixelshuffle(N, N, kernel_size=3, stride=2), nn.BatchNorm2d(N), nn.ReLU(inplace=True),
            deconv_pixelshuffle(N, N, kernel_size=3, stride=2), nn.BatchNorm2d(N), nn.ReLU(inplace=True),
            deconv_pixelshuffle(N, 3, kernel_size=5, stride=2),
        )
        # h_a: Hyper Encoder
        self.h_a = nn.Sequential(
            conv(M, N, kernel_size=3, stride=1), nn.ReLU(inplace=True),
            conv(N, N, kernel_size=3, stride=2), nn.ReLU(inplace=True),
            conv(N, N, kernel_size=3, stride=2)
        )
        # h_s: Hyper-Prior Decoder
        self.h_s = nn.Sequential(
            deconv_pixelshuffle(N, N, kernel_size=3, stride=2), nn.ReLU(inplace=True),
            deconv_pixelshuffle(N, N, kernel_size=3, stride=2), nn.ReLU(inplace=True),
            conv(N, M * 2, kernel_size=3, stride=1)
        )
        self.entropy_bottleneck = EntropyBottleneck(N)
        self.gaussian_conditional = GaussianConditional(None)
        self.apply(self._init_weights)

    def forward(self, x):
        y = self.g_a(x)
        z = self.h_a(y)
        z_hat, z_likelihoods = self.entropy_bottleneck(z)
        gaussian_params = self.h_s(z_hat)
        scales_hat, means_hat = gaussian_params.chunk(2, 1)
        y_hat, y_likelihoods = self.gaussian_conditional(y, scales_hat, means=means_hat)
        x_hat = self.g_s(y_hat)
        return {
            "x_hat": x_hat, "likelihoods": {"y": y_likelihoods, "z": z_likelihoods},
            "y_hat": y_hat, "z_hat": z_hat
        }

    def aux_loss(self):
        return sum(m.loss() for m in self.modules() if isinstance(m, EntropyBottleneck))

    def _init_weights(self, m):
        if isinstance(m, (nn.Conv2d, nn.ConvTranspose2d)):
            nn.init.kaiming_normal_(m.weight, mode='fan_out', nonlinearity='relu')
            if m.bias is not None: nn.init.constant_(m.bias, 0)

    def update(self, scale_table=None, force=False):
        if scale_table is None: scale_table = get_scale_table()
        self.gaussian_conditional.update_scale_table(scale_table, force=force)
        updated = any(m.update(force=force) for m in self.modules() if isinstance(m, EntropyBottleneck))
        return updated

    def load_state_dict(self, state_dict, strict=True):
        update_registered_buffers(
            self.entropy_bottleneck, "entropy_bottleneck",
            ["_quantized_cdf", "_offset", "_cdf_length"], state_dict,
        )
        update_registered_buffers(
            self.gaussian_conditional, "gaussian_conditional",
            ["_quantized_cdf", "_offset", "_cdf_length", "scale_table"], state_dict,
        )
        super().load_state_dict(state_dict, strict=strict)

    @classmethod
    def from_state_dict(cls, state_dict):
        try:
            N = state_dict['g_a.0.weight'].size(0)
        except:
            N = 128
        try:
            M = state_dict['g_a.9.weight'].size(0)
        except:
            M = 192
        print(f"åµæ¸¬åˆ°æ¨¡å‹çµæ§‹: N={N}, M={M}")
        net = cls(N, M)
        net.load_state_dict(state_dict, strict=False)
        return net

    def compress(self, x):
        y = self.g_a(x)
        z = self.h_a(y)
        z_strings = self.entropy_bottleneck.compress(z)
        z_hat = self.entropy_bottleneck.decompress(z_strings, z.size()[-2:])
        gaussian_params = self.h_s(z_hat)
        scales_hat, means_hat = gaussian_params.chunk(2, 1)
        indexes = self.gaussian_conditional.build_indexes(scales_hat)
        y_strings = self.gaussian_conditional.compress(y, indexes, means=means_hat)
        return {"strings": [y_strings, z_strings], "shape": z.size()[-2:]}

    def decompress(self, strings, shape):
        assert isinstance(strings, list) and len(strings) == 2
        z_hat = self.entropy_bottleneck.decompress(strings[1], shape)
        gaussian_params = self.h_s(z_hat)
        scales_hat, means_hat = gaussian_params.chunk(2, 1)
        indexes = self.gaussian_conditional.build_indexes(scales_hat)
        y_hat = self.gaussian_conditional.decompress(strings[0], indexes, means=means_hat)
        x_hat = self.g_s(y_hat).clamp_(0, 1)
        return {"x_hat": x_hat}


# ==============================================================================
# è¼”åŠ©å‡½å¼
# ==============================================================================

# å¿…é ˆè¨»å†Šä½ çš„æ¨¡å‹ï¼Œ`load_checkpoint` æ‰èƒ½é€éåç¨±æ‰¾åˆ°å®ƒ
architectures = {
    "simple_conv_student": SimpleConvStudentModel
}

torch.backends.cudnn.deterministic = True
torch.set_num_threads(1)
IMG_EXTENSIONS = (".jpg", ".jpeg", ".png", ".ppm", ".bmp", ".pgm", ".tif", ".tiff", ".webp")


def collect_images(rootpath: str) -> List[str]:
    return [os.path.join(rootpath, f) for f in os.listdir(rootpath) if
            os.path.splitext(f)[-1].lower() in IMG_EXTENSIONS]


def psnr(a: torch.Tensor, b: torch.Tensor) -> float:
    mse = F.mse_loss(a, b).item()
    return -10 * math.log10(mse) if mse > 0 else float('inf')


def read_image(filepath: str) -> torch.Tensor:
    assert os.path.isfile(filepath)
    img = Image.open(filepath).convert("RGB")
    return transforms.ToTensor()(img)


# ==============================================================================
# æ¨è«– (Inference) å‡½å¼ (å„²å­˜ .bin æª”æ¡ˆ)
# ==============================================================================
@torch.no_grad()
def inference(model, x, save=False, output_dir=None, base_filename=None, patch_index=None):
    x = x.unsqueeze(0)
    h, w = x.size(2), x.size(3)
    p = 64
    new_h = (h + p - 1) // p * p
    new_w = (w + p - 1) // p * p
    padding_left = (new_w - w) // 2
    padding_right = new_w - w - padding_left
    padding_top = (new_h - h) // 2
    padding_bottom = new_h - h - padding_top
    x_padded = F.pad(x, (padding_left, padding_right, padding_top, padding_bottom), mode="constant", value=0)

    start = time.time()
    out_enc = model.compress(x_padded)
    enc_time = time.time() - start

    start = time.time()
    out_dec = model.decompress(out_enc["strings"], out_enc["shape"])
    dec_time = time.time() - start

    out_dec["x_hat"] = F.pad(out_dec["x_hat"], (-padding_left, -padding_right, -padding_top, -padding_bottom))
    num_pixels = x.size(0) * x.size(2) * x.size(3)
    bpp = sum(len(s[0]) for s in out_enc["strings"]) * 8.0 / num_pixels

    if save and output_dir is not None and base_filename is not None:
        # --- å„²å­˜è§£å£“ç¸®çš„ .png æª”æ¡ˆ ---
        reconstructed_img = transforms.ToPILImage()(out_dec["x_hat"].squeeze().cpu())
        output_filepath = os.path.join(output_dir, f"{base_filename}_reconstructed.png")
        reconstructed_img.save(output_filepath)

        # --- å„²å­˜ .bin æª”æ¡ˆ ---
        bin_filepath = os.path.join(output_dir, f"{base_filename}.bin")
        y_string = out_enc["strings"][0][0]
        z_string = out_enc["strings"][1][0]
        shape = out_enc["shape"]

        try:
            with open(bin_filepath, "wb") as f:
                f.write(shape[0].to_bytes(2, 'little', signed=False))
                f.write(shape[1].to_bytes(2, 'little', signed=False))
                f.write(len(z_string).to_bytes(4, 'little', signed=False))
                f.write(z_string)
                f.write(len(y_string).to_bytes(4, 'little', signed=False))
                f.write(y_string)
        except Exception as e:
            print(f"Error saving bitstream: {e}")

    return {"psnr": psnr(x, out_dec["x_hat"]), "ms-ssim": ms_ssim(x, out_dec["x_hat"], data_range=1.0).item(),
            "bpp": bpp, "encoding_time": enc_time, "decoding_time": dec_time}


# ==============================================================================
# (inference_entropy_estimation å‡½å¼ä¿æŒä¸è®Š)
# ==============================================================================
@torch.no_grad()
def inference_entropy_estimation(model, x):
    x = x.unsqueeze(0)
    start = time.time()
    out_net = model.forward(x)
    elapsed_time = time.time() - start
    num_pixels = x.size(0) * x.size(2) * x.size(3)
    bpp = sum(
        (torch.log(likelihoods).sum() / (-math.log(2) * num_pixels)) for likelihoods in
        out_net["likelihoods"].values())
    return {"psnr": psnr(x, out_net["x_hat"]), "bpp": bpp.item(), "encoding_time": elapsed_time / 2.0,
            "decoding_time": elapsed_time / 2.0}


# ==============================================================================
# (load_pretrained å‡½å¼ä¿æŒä¸è®Š)
# ==============================================================================
def load_pretrained(model: str, metric: str, quality: int) -> nn.Module:
    return pretrained_models[model](quality=quality, metric=metric, pretrained=True).eval()


# ==============================================================================
# (load_checkpoint å‡½å¼ä¿æŒä¸è®Š)
# ==============================================================================
def load_checkpoint(arch: str, checkpoint_path: str) -> nn.Module:
    print(f"æ­£åœ¨å¾ {checkpoint_path} è¼‰å…¥æ¬Šé‡...")
    checkpoint = torch.load(checkpoint_path, map_location=lambda storage, loc: storage)
    state_dict = checkpoint.get("state_dict", checkpoint)

    clean_state_dict = OrderedDict()
    is_dataparallel = False
    for k, v in state_dict.items():
        if k.startswith('module.'):
            is_dataparallel = True
            name = k[7:]
        else:
            name = k
        clean_state_dict[name] = v

    if is_dataparallel:
        print("åµæ¸¬åˆ° 'module.' å‰ç¶´ï¼Œå·²è‡ªå‹•ç§»é™¤ã€‚")

    # ç¢ºä¿ `architectures` å­—å…¸æœ‰è¢«å¡«å……
    if arch not in architectures:
        print(f"éŒ¯èª¤: æ¶æ§‹ '{arch}' æœªåœ¨ 'architectures' å­—å…¸ä¸­è¨»å†Šã€‚")
        sys.exit(1)

    return architectures[arch].from_state_dict(clean_state_dict).eval()


# ==============================================================================
# âœ¨âœ¨âœ¨ eval_model å‡½å¼ (å·²æ›´æ–°ï¼ŒåŒ…å« tar å’Œ md5sum) âœ¨âœ¨âœ¨
# ==============================================================================
def eval_model(model, filepaths, entropy_estimation=False, half=False, save=False, output_dir=None, use_tar=False,
               keep_bins=False):
    device = next(model.parameters()).device
    metrics = defaultdict(float)
    to_tensor_transform = transforms.ToTensor()

    PATCH_SIZE = 256
    EXPECTED_W = 4096
    EXPECTED_H = 3072

    for i, f in enumerate(filepaths):
        print(f"\n--- æ­£åœ¨é–‹å•Ÿå¤§å‹å½±åƒ {i + 1}/{len(filepaths)}: {os.path.basename(f)} ---")

        img_large = None
        try:
            img_large = Image.open(f).convert("RGB")
        except Exception as e:
            print(f"  éŒ¯èª¤ï¼šç„¡æ³•è®€å–å½±åƒ {f}ã€‚éŒ¯èª¤è¨Šæ¯: {e}ã€‚è·³éæ­¤æª”æ¡ˆã€‚")
            if img_large: img_large.close()
            continue

        img_w, img_h = img_large.size
        if img_w != EXPECTED_W or img_h != EXPECTED_H:
            print(f"  è­¦å‘Šï¼šå½±åƒ '{os.path.basename(f)}' çš„å¤§å°ä¸æ˜¯ {EXPECTED_W}x{EXPECTED_H} (è€Œæ˜¯ {img_w}x{img_h})ã€‚")

        num_patches_x = img_w // PATCH_SIZE
        num_patches_y = img_h // PATCH_SIZE
        total_patches = num_patches_y * num_patches_x

        if total_patches == 0:
            print(f"  éŒ¯èª¤ï¼šå½±åƒå¤ªå°ï¼Œç„¡æ³•åˆ‡å‰²æˆ {PATCH_SIZE}x{PATCH_SIZE} çš„å€å¡Šã€‚è·³éæ­¤å½±åƒã€‚")
            img_large.close()
            continue

        print(f"  å½±åƒå°‡è¢«åˆ‡å‰²æˆ {num_patches_y} (é«˜) x {num_patches_x} (å¯¬) = {total_patches} å¼µ 256x256 å€å¡Šã€‚")

        base_filename_large = os.path.splitext(os.path.basename(f))[0]

        # ã€ä¿®æ”¹ã€‘å»ºç«‹å°ˆå±¬å­è³‡æ–™å¤¾
        # å€å¡Šå°‡å„²å­˜åˆ°: output_dir/Tokyo_cropped_4096x3072/
        current_image_patch_dir = os.path.join(output_dir, base_filename_large)
        if save:
            os.makedirs(current_image_patch_dir, exist_ok=True)
            print(f"  å€å¡Šå°‡å„²å­˜è‡³: {current_image_patch_dir}")

        patch_metrics_list = []
        patch_bin_files_list = []  # ã€æ–°å¢ã€‘ç”¨æ–¼å„²å­˜ .bin æª”æ¡ˆçš„ç›¸å°è·¯å¾‘
        patch_index = 0

        try:
            # å·¢ç‹€è¿´åœˆï¼šå¾ä¸Šåˆ°ä¸‹ (y), å¾å·¦åˆ°å³ (x)
            for y_idx in range(num_patches_y):
                for x_idx in range(num_patches_x):

                    print(f"    è™•ç†å€å¡Š {patch_index + 1}/{total_patches} (Row {y_idx}, Col {x_idx})...", end="")

                    left = x_idx * PATCH_SIZE
                    upper = y_idx * PATCH_SIZE
                    right = left + PATCH_SIZE
                    lower = upper + PATCH_SIZE
                    box = (left, upper, right, lower)
                    patch_img = img_large.crop(box)
                    x_patch = to_tensor_transform(patch_img).to(device)

                    if half:
                        model = model.half()
                        x_patch = x_patch.half()

                    patch_base_filename = f"{base_filename_large}_patch_{patch_index:03d}"

                    if not entropy_estimation:
                        rv = inference(model,
                                       x_patch,
                                       save,
                                       current_image_patch_dir,  # <-- å‚³å…¥å°ˆå±¬å­è³‡æ–™å¤¾
                                       patch_base_filename,
                                       patch_index)

                        # ã€æ–°å¢ã€‘æ”¶é›† .bin æª”æ¡ˆè·¯å¾‘
                        if save and use_tar:
                            bin_name = f"{patch_base_filename}.bin"
                            relative_bin_path = os.path.join(base_filename_large, bin_name)
                            patch_bin_files_list.append(relative_bin_path)
                    else:
                        rv = inference_entropy_estimation(model, x_patch)

                    print(f" PSNR: {rv['psnr']:.2f} dB, BPP: {rv['bpp']:.4f}")
                    patch_metrics_list.append(rv)
                    patch_index += 1

                    del patch_img
                    del x_patch

        finally:
            if img_large:
                img_large.close()
                print(f"  --- å·²é—œé–‰å½±åƒæª”æ¡ˆ: {os.path.basename(f)} ---")

        # --- è™•ç†å®Œä¸€å¼µå¤§åœ– (192å€‹å€å¡Š) ---

        # (è¨ˆç®—å¹³å‡æŒ‡æ¨™)
        avg_metrics_large = defaultdict(float)
        if not patch_metrics_list: continue
        for rv in patch_metrics_list:
            for k, v in rv.items():
                avg_metrics_large[k] += v
        print(f"  --- å¤§å‹å½±åƒ '{os.path.basename(f)}' å¹³å‡çµ±è¨ˆ ---")
        for k, v in avg_metrics_large.items():
            avg_metrics_large[k] = v / total_patches
            print(f"    Avg. {k}: {avg_metrics_large[k]:.4f}")
        for k, v in avg_metrics_large.items():
            metrics[k] += v

        # --- ã€æ–°å¢ã€‘åŸ·è¡Œ Gnu tar å’Œ md5sum ---
        if save and use_tar and patch_bin_files_list:
            print(f"  --- æ­£åœ¨ä½¿ç”¨ Gnu tar æ‰“åŒ… {len(patch_bin_files_list)} å€‹ .bin æª”æ¡ˆ... ---")

            tar_filename = f"{base_filename_large}.tar"
            tar_filepath = os.path.join(output_dir, tar_filename)
            tar_command = ["tar", "-cf", tar_filename]
            tar_command.extend(patch_bin_files_list)  # åŠ å…¥æ‰€æœ‰ .bin æª”æ¡ˆçš„ç›¸å°è·¯å¾‘

            try:
                # 1. åŸ·è¡Œ tar
                subprocess.run(tar_command, check=True, cwd=output_dir, stdout=subprocess.DEVNULL,
                               stderr=subprocess.PIPE)
                print(f"  âœ… æˆåŠŸæ‰“åŒ…: {tar_filepath}")

                # 2. åŸ·è¡Œ md5sum
                try:
                    md5_filename = f"{tar_filename}.md5"
                    md5_filepath = os.path.join(output_dir, md5_filename)
                    md5_command = ["md5sum", tar_filename]

                    md5_result = subprocess.run(
                        md5_command, check=True, cwd=output_dir,
                        capture_output=True, text=True, encoding='utf-8'
                    )

                    md5_checksum_output = md5_result.stdout.strip()
                    with open(md5_filepath, "w", encoding='utf-8') as md5_f:
                        md5_f.write(md5_checksum_output + "\n")
                    print(f"  âœ… æˆåŠŸå»ºç«‹ Checksum: {md5_filename}")

                except subprocess.CalledProcessError as e:
                    print(f"  âŒ éŒ¯èª¤: 'md5sum' å‘½ä»¤åŸ·è¡Œå¤±æ•— (code {e.returncode})ã€‚")
                    print(f"  éŒ¯èª¤è¨Šæ¯: {e.stderr.decode()}")
                except FileNotFoundError:
                    print("  âŒ éŒ¯èª¤: 'md5sum' å‘½ä»¤æœªæ‰¾åˆ°ã€‚è«‹ç¢ºä¿ md5sum å·²å®‰è£ (é€šå¸¸ busybox æœƒåŒ…å«)ã€‚")

                # 3. åˆªé™¤æš«å­˜æª” (å¦‚æœéœ€è¦)
                if not keep_bins:
                    shutil.rmtree(current_image_patch_dir)
                    print(f"  ğŸ—‘ï¸ å·²åˆªé™¤æš«å­˜å€å¡Šè³‡æ–™å¤¾: {current_image_patch_dir}")

            except subprocess.CalledProcessError as e:
                print(f"  âŒ éŒ¯èª¤: 'tar' å‘½ä»¤åŸ·è¡Œå¤±æ•— (code {e.returncode})ã€‚")
                print(f"  éŒ¯èª¤è¨Šæ¯: {e.stderr.decode()}")
            except FileNotFoundError:
                print("  âŒ éŒ¯èª¤: 'tar' å‘½ä»¤æœªæ‰¾åˆ°ã€‚è«‹ç¢ºä¿ tar å·²å®‰è£ (é€šå¸¸ busybox æœƒåŒ…å«)ã€‚")
        # --- tar/md5sum é‚è¼¯çµæŸ ---

    # --- è™•ç†å®Œæ‰€æœ‰å¤§åœ– ---
    if not filepaths:
        print("éŒ¯èª¤ï¼šæœªæä¾›ä»»ä½•å½±åƒé€²è¡Œè©•ä¼°ã€‚")
        return metrics

    for k, v in metrics.items():
        metrics[k] = v / len(filepaths)

    if save:
        print(f"\nè™•ç†å®Œæˆã€‚å·²å„²å­˜æ‰€æœ‰æª”æ¡ˆè‡³: {output_dir}")

    return metrics


# ==============================================================================
# âœ¨âœ¨âœ¨ setup_args å‡½å¼ (å·²æ›´æ–°ï¼ŒåŒ…å« tar å’Œ md5sum) âœ¨âœ¨âœ¨
# ==============================================================================
def setup_args():
    parent_parser = argparse.ArgumentParser(add_help=False)
    parent_parser.add_argument("dataset", type=str, help="dataset path (åŒ…å« 4096x3072 å½±åƒçš„è³‡æ–™å¤¾)")
    parent_parser.add_argument("-a", "--architecture", type=str, required=True,
                               help="model architecture (e.g., simple_conv_student)")
    parent_parser.add_argument("-c", "--entropy-coder", choices=compressai.available_entropy_coders(),
                               default=compressai.available_entropy_coders()[0],
                               help="entropy coder (default: %(default)s)")
    parent_parser.add_argument("--cuda", action="store_true", help="enable CUDA")
    parent_parser.add_argument("--half", action="store_true", help="convert model to half floating point (fp16)")
    parent_parser.add_argument("--entropy-estimation", action="store_true",
                               help="use evaluated entropy estimation (no entropy coding)")
    parent_parser.add_argument("-v", "--verbose", action="store_true", help="verbose mode")
    parent_parser.add_argument("--save", action="store_true", help="å„²å­˜åˆ‡å‰²å¾Œçš„ .bin å’Œè§£å£“ç¸®çš„ .png æª”æ¡ˆ")

    # --- ã€æ–°å¢ã€‘ tar å’Œ md5sum ç›¸é—œåƒæ•¸ ---
    parent_parser.add_argument(
        "--use-tar",
        action="store_true",
        help="[Linux/macOS] å°‡æ¯å¼µå¤§åœ–çš„ .bin å€å¡Šæ‰“åŒ…æˆå–®ä¸€ .tar æª” (éœ€å®‰è£ tar)"
    )
    parent_parser.add_argument(
        "--keep-bins",
        action="store_true",
        help="èˆ‡ --use-tar ä¸€èµ·ä½¿ç”¨æ™‚ï¼Œæ‰“åŒ…å¾Œä¿ç•™åŸå§‹çš„ .bin å€å¡Šæª”æ¡ˆ"
    )
    # --- ã€æ–°å¢çµæŸã€‘ ---

    parent_parser.add_argument("-o", "--output_dir", type=str, default="no_header",
                               help="å„²å­˜ 192 å€‹å€å¡Šæª”æ¡ˆçš„è³‡æ–™å¤¾ (default: %(default)s)")

    parser = argparse.ArgumentParser(description="Evaluate a model by tiling large images.", add_help=True)
    subparsers = parser.add_subparsers(help="model source", dest="source")

    pretrained_parser = subparsers.add_parser("pretrained", parents=[parent_parser])
    pretrained_parser.add_argument("-m", "--metric", type=str, choices=["mse", "ms-ssim"], default="mse",
                                   help="metric trained against (default: %(default)s)")
    pretrained_parser.add_argument("-q", "--quality", dest="qualities", nargs="+", type=int, default=(1,))

    checkpoint_parser = subparsers.add_parser("checkpoint", parents=[parent_parser])
    checkpoint_parser.add_argument("-p", "--path", dest="paths", type=str, nargs="*", required=True,
                                   help="checkpoint path")
    return parser


# ==============================================================================
# âœ¨âœ¨âœ¨ main å‡½å¼ (å·²æ›´æ–°ï¼ŒåŒ…å« tar å’Œ md5sum) âœ¨âœ¨âœ¨
# ==============================================================================
def main(argv):
    parser = setup_args()
    args = parser.parse_args(argv)
    if not args.source:
        print("Error: missing 'checkpoint' or 'pretrained' source.", file=sys.stderr)
        parser.print_help()
        raise SystemExit(1)

    filepaths = collect_images(args.dataset)
    if len(filepaths) == 0:
        print(f"Error: åœ¨ '{args.dataset}' è³‡æ–™å¤¾ä¸­æ‰¾ä¸åˆ°ä»»ä½•å½±åƒã€‚", file=sys.stderr)
        raise SystemExit(1)

    print(f"åœ¨ {args.dataset} ä¸­æ‰¾åˆ° {len(filepaths)} å¼µå½±åƒã€‚")

    if args.save:
        os.makedirs(args.output_dir, exist_ok=True)
        print(f"åˆ‡å‰²å¾Œçš„ .bin å’Œ .png æª”æ¡ˆå°‡å„²å­˜è‡³: {args.output_dir}")
        if args.use_tar:
            print("å°‡å•Ÿç”¨ 'tar' æ‰“åŒ…åŠŸèƒ½ (æ¯å¼µå¤§åœ–ä¸€å€‹ .tar æª”)ã€‚")

    compressai.set_entropy_coder(args.entropy_coder)

    if args.source == "pretrained":
        runs = sorted(args.qualities)
        opts = (args.architecture, args.metric)
        load_func = load_pretrained
        log_fmt = "\rEvaluating {0} | {run:d}"
    elif args.source == "checkpoint":
        runs = args.paths
        opts = (args.architecture,)
        load_func = load_checkpoint
        log_fmt = "\rEvaluating {run:s}"

    results = defaultdict(list)
    for run in runs:
        if args.verbose:
            sys.stderr.write(log_fmt.format(*opts, run=run))
            sys.stderr.flush()

        model = load_func(*opts, run)
        if args.cuda and torch.cuda.is_available():
            model = model.to("cuda")
            print("æ¨¡å‹å·²ç§»è‡³ CUDA")
        else:
            model = model.to("cpu")
            print("æ¨¡å‹å·²ç§»è‡³ CPU")

        if args.half and not args.cuda:
            print("è­¦å‘Š: --half åƒæ•¸é€šå¸¸èˆ‡ --cuda ä¸€èµ·ä½¿ç”¨ã€‚åœ¨ CPU ä¸Šä½¿ç”¨ FP16 å¯èƒ½æœƒæ›´æ…¢æˆ–ä¸å—æ”¯æ´ã€‚")

        if args.source == "checkpoint":
            print("æ­£åœ¨æ›´æ–°æ¨¡å‹ (update CDFs)...")
            model.update(force=True)
            print("æ¨¡å‹æ›´æ–°å®Œç•¢ã€‚")

        # ã€ä¿®æ”¹ã€‘å‚³å…¥æ–°åƒæ•¸
        metrics = eval_model(
            model,
            filepaths,
            args.entropy_estimation,
            args.half,
            args.save,
            args.output_dir,
            args.use_tar,  # <-- å‚³å…¥ tar åƒæ•¸
            args.keep_bins  # <-- å‚³å…¥ keep åƒæ•¸
        )

        for k, v in metrics.items():
            results[k].append(v)

    if args.verbose:
        sys.stderr.write("\n")
        sys.stderr.flush()

    description = ("entropy estimation" if args.entropy_estimation else args.entropy_coder)
    output = {"name": args.architecture, "description": f"Inference ({description})", "results": results}

    print("\n--- ç¸½é«”å¹³å‡æŒ‡æ¨™ (æ‰€æœ‰å¤§å‹å½±åƒçš„å¹³å‡) ---")
    print(json.dumps(output, indent=2))


if __name__ == "__main__":
    main(sys.argv[1:])
