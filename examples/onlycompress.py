import argparse
import os
import sys
import glob
import re
import math
from collections import OrderedDict

import torch
import torch.nn.functional as F
from torchvision import transforms
from PIL import Image

# ==============================================================================
# è¨­å®šï¼šåŒ¯å…¥æ¨¡å‹
# ==============================================================================
try:
    from conv2 import SimpleConvStudentModel
except ImportError:
    print("éŒ¯èª¤: æ‰¾ä¸åˆ° conv2.pyï¼Œè«‹ç¢ºèªæª”æ¡ˆä½ç½®ã€‚")
    sys.exit(1)

# å˜—è©¦åŒ¯å…¥ rasterio (è‹¥åŸå§‹åœ–æ˜¯ TIF éœ€è¦)
try:
    import rasterio
except ImportError:
    rasterio = None
    # å˜—è©¦åŒ¯å…¥ ms_ssim (ç”¨æ–¼è¨ˆç®—åˆ†æ•¸)
try:
    from pytorch_msssim import ms_ssim

    HAS_MSSSIM = True
except ImportError:
    print("è­¦å‘Š: æœªå®‰è£ pytorch_msssimï¼Œå°‡è·³é SSIM è¨ˆç®—ã€‚(å¯åŸ·è¡Œ pip install pytorch-msssim å®‰è£)")
    HAS_MSSSIM = False


# ==============================================================================
# Monkey Patching: æ³¨å…¥è§£å£“ç¸®æ–¹æ³•
# ==============================================================================
def decompress_method(self, strings, shape):
    assert isinstance(strings, list) and len(strings) == 2
    z_hat = self.entropy_bottleneck.decompress(strings[1], shape)
    gaussian_params = self.h_s(z_hat)
    scales_hat, means_hat = gaussian_params.chunk(2, 1)
    indexes = self.gaussian_conditional.build_indexes(scales_hat)
    y_hat = self.gaussian_conditional.decompress(strings[0], indexes, means=means_hat)
    x_hat = self.g_s(y_hat).clamp_(0, 1)
    return {"x_hat": x_hat}


SimpleConvStudentModel.decompress = decompress_method


# ==============================================================================
# å·¥å…·å‡½å¼
# ==============================================================================
def load_bin_file(bin_path):
    """è®€å– .bin æª”æ¡ˆä¸¦é‚„åŸæˆ strings å’Œ shape"""
    with open(bin_path, "rb") as f:
        # è®€å– shape
        h = int.from_bytes(f.read(2), 'little')
        w = int.from_bytes(f.read(2), 'little')
        shape = (h, w)

        # è®€å– z_string
        len_z = int.from_bytes(f.read(4), 'little')
        z_str = f.read(len_z)

        # è®€å– y_string
        len_y = int.from_bytes(f.read(4), 'little')
        y_str = f.read(len_y)

    return {"strings": [[y_str], [z_str]], "shape": shape}


@torch.no_grad()
def process_decompress(model, bin_path, device):
    data = load_bin_file(bin_path)
    out_dec = model.decompress(data["strings"], data["shape"])
    x_hat = out_dec["x_hat"]

    # è™•ç† Patch å¤§å° (é è¨­ 256)
    target_h, target_w = 256, 256
    curr_h, curr_w = x_hat.size(2), x_hat.size(3)

    if curr_h != target_h or curr_w != target_w:
        padding_left = (curr_w - target_w) // 2
        padding_top = (curr_h - target_h) // 2
        x_hat = x_hat[:, :, padding_top:padding_top + target_h, padding_left:padding_left + target_w]

    return x_hat


def psnr(a: torch.Tensor, b: torch.Tensor) -> float:
    """è¨ˆç®— PSNR"""
    mse = F.mse_loss(a, b).item()
    return -10 * math.log10(mse) if mse > 0 else float('inf')


def read_original_image(filepath: str) -> torch.Tensor:
    """è®€å–åŸå§‹åœ–ç‰‡ä¸¦è½‰ç‚º Tensor (èˆ‡ä½ åŸæœ¬çš„é‚è¼¯ä¸€è‡´)"""
    ext = os.path.splitext(filepath)[-1].lower()
    if ext in ['.tif', '.tiff']:
        if rasterio is None: raise RuntimeError("éœ€å®‰è£ rasterio æ‰èƒ½è®€å– TIF")
        SCALE = 10000.0
        with rasterio.open(filepath) as src:
            raw_data = src.read().astype(np.float32)
        if np.isnan(raw_data).any(): raw_data = np.nan_to_num(raw_data)
        rgb_data = raw_data[:3, :, :] if raw_data.shape[0] >= 3 else raw_data
        clipped_data = np.clip(rgb_data, 0.0, 10000.0)
        return torch.from_numpy(clipped_data / SCALE)
    else:
        img = Image.open(filepath).convert("RGB")
        return transforms.ToTensor()(img)


def load_checkpoint(checkpoint_path):
    print(f"Loading checkpoint: {checkpoint_path}")
    checkpoint = torch.load(checkpoint_path, map_location='cpu')
    state_dict = checkpoint.get("state_dict", checkpoint)
    new_state_dict = OrderedDict()
    for k, v in state_dict.items():
        name = k[7:] if k.startswith('module.') else k
        new_state_dict[name] = v

    N, M = 128, 192
    try:
        N = new_state_dict['g_a.0.weight'].size(0)
        keys = sorted([k for k in new_state_dict.keys() if 'g_a' in k and 'weight' in k])
        M = new_state_dict[keys[-1]].size(0)
    except:
        pass

    model = SimpleConvStudentModel(N=N, M=M)
    model.load_state_dict(new_state_dict, strict=False)
    return model.eval()


# ==============================================================================
# ä¸»ç¨‹å¼
# ==============================================================================
def main():
    parser = argparse.ArgumentParser(description="Image Decompression & PSNR Tool")
    parser.add_argument("bin_dir", type=str, help="Directory containing .bin files")
    parser.add_argument("-p", "--checkpoint", type=str, required=True, help="Path to .pth model")
    # æ–°å¢åƒæ•¸ï¼šåŸå§‹åœ–ç‰‡è·¯å¾‘
    parser.add_argument("--original", type=str, default=None, help="Path to original image (for PSNR calculation)")
    parser.add_argument("--cuda", action="store_true", default=True)
    args = parser.parse_args()

    device = "cuda" if args.cuda and torch.cuda.is_available() else "cpu"
    PATCH_SIZE = 256

    # 1. æœå°‹ .bin æª”æ¡ˆ
    bin_files = glob.glob(os.path.join(args.bin_dir, "*.bin"))
    if not bin_files:
        print(f"åœ¨ {args.bin_dir} æ‰¾ä¸åˆ°ä»»ä½• .bin æª”æ¡ˆ")
        sys.exit(1)

    print(f"æ‰¾åˆ° {len(bin_files)} å€‹å£“ç¸®æª”ï¼Œæº–å‚™è§£å£“ç¸®...")

    # 2. åˆ†ææª”å
    max_row, max_col = 0, 0
    pattern = re.compile(r"_row(\d+)_col(\d+)\.bin$")
    valid_files = []
    base_name = ""

    for f in bin_files:
        match = pattern.search(f)
        if match:
            r, c = int(match.group(1)), int(match.group(2))
            max_row = max(max_row, r)
            max_col = max(max_col, c)
            valid_files.append((r, c, f))
            if base_name == "":
                base_name = os.path.basename(f).replace(match.group(0), "")

    # è¨ˆç®—ç•«å¸ƒå¤§å°
    canvas_w = (max_col + 1) * PATCH_SIZE
    canvas_h = (max_row + 1) * PATCH_SIZE
    print(f"åµæ¸¬åˆ°çŸ©é™£: {max_row + 1}x{max_col + 1} | é‡å»ºç•«å¸ƒ: {canvas_w}x{canvas_h}")

    full_recon_img = Image.new('RGB', (canvas_w, canvas_h))

    # 3. è¼‰å…¥æ¨¡å‹
    model = load_checkpoint(args.checkpoint).to(device)
    model.update(force=True)

    # 4. è§£å£“ç¸®ä¸¦æ‹¼è²¼
    count = 0
    for r, c, fpath in valid_files:
        count += 1
        print(f"è§£å£“ç¸®: {os.path.basename(fpath)} ({count}/{len(valid_files)})", end='\r')
        x_hat = process_decompress(model, fpath, device)
        rec_tensor = x_hat.squeeze().cpu().clamp(0, 1)
        rec_patch_pil = transforms.ToPILImage()(rec_tensor)

        left = c * PATCH_SIZE
        upper = r * PATCH_SIZE
        full_recon_img.paste(rec_patch_pil, (left, upper))

    print("\nè§£å£“ç¸®å®Œæˆï¼Œæ­£åœ¨å„²å­˜å¤§åœ–...")

    output_filename = f"{base_name}_RECONSTRUCTED.png"
    output_path = os.path.join(args.bin_dir, output_filename)
    full_recon_img.save(output_path)
    print(f"å®Œæ•´é‚„åŸåœ–å·²å„²å­˜è‡³: {output_path}")

    # ==========================================================================
    # 5. è¨ˆç®— PSNR (å¦‚æœä½¿ç”¨è€…æœ‰æä¾›åŸå§‹åœ–)
    # ==========================================================================
    if args.original:
        print("-" * 40)
        print("æ­£åœ¨è¨ˆç®— PSNR...")

        if not os.path.exists(args.original):
            print(f"éŒ¯èª¤: æ‰¾ä¸åˆ°åŸå§‹åœ–ç‰‡ {args.original}")
            return

        # è®€å–åŸå§‹åœ–
        try:
            # ä½¿ç”¨èˆ‡è¨“ç·´æ™‚ç›¸åŒçš„è®€å–é‚è¼¯ (æ­£è¦åŒ–åˆ° 0-1)
            gt_tensor = read_original_image(args.original)

            # è®€å–å‰›é‡å»ºå¥½çš„åœ– (è½‰ç‚º Tensor 0-1)
            rec_tensor = transforms.ToTensor()(full_recon_img)

            # ç¢ºä¿å°ºå¯¸ä¸€è‡´ (é‡å°é‚Šç·£å¯èƒ½è¢«è£åˆ‡çš„æƒ…æ³)
            # å¦‚æœé‡å»ºåœ–æ¯”åŸå§‹åœ–å° (å› ç‚º patch æ²’åˆ‡æ»¿)ï¼Œå‰‡è£åˆ‡åŸå§‹åœ–ä¾†å°é½Š
            # å¦‚æœé‡å»ºåœ–æ¯”åŸå§‹åœ–å¤§ (å› ç‚º padding)ï¼Œå‰‡è£åˆ‡é‡å»ºåœ–
            h_gt, w_gt = gt_tensor.shape[1], gt_tensor.shape[2]
            h_rec, w_rec = rec_tensor.shape[1], rec_tensor.shape[2]

            min_h = min(h_gt, h_rec)
            min_w = min(w_gt, w_rec)

            gt_tensor = gt_tensor[:, :min_h, :min_w]
            rec_tensor = rec_tensor[:, :min_h, :min_w]

            # è¨ˆç®—æ•¸å€¼
            val_psnr = psnr(gt_tensor, rec_tensor)
            val_msssim = ms_ssim(gt_tensor.unsqueeze(0), rec_tensor.unsqueeze(0), data_range=1.0).item()

            print(f"åŸå§‹åœ–å°ºå¯¸: {w_gt}x{h_gt}")
            print(f"é‡å»ºåœ–å°ºå¯¸: {w_rec}x{h_rec}")
            print(f"æ¯”å°å€åŸŸ:   {min_w}x{min_h}")
            print("-" * 40)
            print(f"ğŸš€ PSNR:    {val_psnr:.4f} dB")
            print(f"ğŸš€ MS-SSIM: {val_msssim:.4f}")
            print("-" * 40)

        except Exception as e:
            print(f"è¨ˆç®— PSNR æ™‚ç™¼ç”ŸéŒ¯èª¤: {e}")
            import traceback
            traceback.print_exc()


if __name__ == "__main__":
    main()